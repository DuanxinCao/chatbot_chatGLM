{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "77019894",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:512\"\n",
    "import torch\n",
    "\n",
    "def torch_gc():\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"clear cache\")\n",
    "        # with torch.cuda.device(DEVICE):\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.ipc_collect()\n",
    "    elif torch.backends.mps.is_available():\n",
    "        try:\n",
    "            from torch.mps import empty_cache\n",
    "            empty_cache()\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(\"如果您使用的是 macOS 建议将 pytorch 版本升级至 2.0.0 或更高版本，以支持及时清理 torch 产生的内存占用。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "78c6e684",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "import re\n",
    "from typing import List\n",
    "SENTENCE_SIZE=100\n",
    "class ChineseTextSplitter(CharacterTextSplitter):\n",
    "    def __init__(self, pdf: bool = False, sentence_size: int = SENTENCE_SIZE, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.pdf = pdf\n",
    "        self.sentence_size = sentence_size\n",
    "\n",
    "    def split_text1(self, text: str) -> List[str]:\n",
    "        if self.pdf:\n",
    "            text = re.sub(r\"\\n{3,}\", \"\\n\", text)\n",
    "            text = re.sub('\\s', ' ', text)\n",
    "            text = text.replace(\"\\n\\n\", \"\")\n",
    "        sent_sep_pattern = re.compile('([﹒﹔﹖﹗．。！？][\"’”」』]{0,2}|(?=[\"‘“「『]{1,2}|$))')  # del ：；\n",
    "        sent_list = []\n",
    "        for ele in sent_sep_pattern.split(text):\n",
    "            if sent_sep_pattern.match(ele) and sent_list:\n",
    "                sent_list[-1] += ele\n",
    "            elif ele:\n",
    "                sent_list.append(ele)\n",
    "        return sent_list\n",
    "\n",
    "    def split_text(self, text: str) -> List[str]:   ##此处需要进一步优化逻辑\n",
    "        if self.pdf:\n",
    "            text = re.sub(r\"\\n{3,}\", r\"\\n\", text)\n",
    "            text = re.sub('\\s', \" \", text)\n",
    "            text = re.sub(\"\\n\\n\", \"\", text)\n",
    "\n",
    "        text = re.sub(r'([;；.!?。！？\\?])([^”’])', r\"\\1\\n\\2\", text)  # 单字符断句符\n",
    "        text = re.sub(r'(\\.{6})([^\"’”」』])', r\"\\1\\n\\2\", text)  # 英文省略号\n",
    "        text = re.sub(r'(\\…{2})([^\"’”」』])', r\"\\1\\n\\2\", text)  # 中文省略号\n",
    "        text = re.sub(r'([;；!?。！？\\?][\"’”」』]{0,2})([^;；!?，。！？\\?])', r'\\1\\n\\2', text)\n",
    "        # 如果双引号前有终止符，那么双引号才是句子的终点，把分句符\\n放到双引号后，注意前面的几句都小心保留了双引号\n",
    "        text = text.rstrip()  # 段尾如果有多余的\\n就去掉它\n",
    "        # 很多规则中会考虑分号;，但是这里我把它忽略不计，破折号、英文双引号等同样忽略，需要的再做些简单调整即可。\n",
    "        ls = [i for i in text.split(\"\\n\") if i]\n",
    "        for ele in ls:\n",
    "            if len(ele) > self.sentence_size:\n",
    "                ele1 = re.sub(r'([,，.][\"’”」』]{0,2})([^,，.])', r'\\1\\n\\2', ele)\n",
    "                ele1_ls = ele1.split(\"\\n\")\n",
    "                for ele_ele1 in ele1_ls:\n",
    "                    if len(ele_ele1) > self.sentence_size:\n",
    "                        ele_ele2 = re.sub(r'([\\n]{1,}| {2,}[\"’”」』]{0,2})([^\\s])', r'\\1\\n\\2', ele_ele1)\n",
    "                        ele2_ls = ele_ele2.split(\"\\n\")\n",
    "                        for ele_ele2 in ele2_ls:\n",
    "                            if len(ele_ele2) > self.sentence_size:\n",
    "                                ele_ele3 = re.sub('( [\"’”」』]{0,2})([^ ])', r'\\1\\n\\2', ele_ele2)\n",
    "                                ele2_id = ele2_ls.index(ele_ele2)\n",
    "                                ele2_ls = ele2_ls[:ele2_id] + [i for i in ele_ele3.split(\"\\n\") if i] + ele2_ls[\n",
    "                                                                                                       ele2_id + 1:]\n",
    "                        ele_id = ele1_ls.index(ele_ele1)\n",
    "                        ele1_ls = ele1_ls[:ele_id] + [i for i in ele2_ls if i] + ele1_ls[ele_id + 1:]\n",
    "\n",
    "                id = ls.index(ele)\n",
    "                ls = ls[:id] + [i for i in ele1_ls if i] + ls[id + 1:]\n",
    "        return ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from langchain.document_loaders import UnstructuredFileLoader, TextLoader\n",
    "\n",
    "filepath = \"/root/caoduanxin/docs/tairQA_cn.txt\"\n",
    "\n",
    "loader = TextLoader(filepath,autodetect_encoding=True)\n",
    "textsplitter = ChineseTextSplitter(pdf=False, sentence_size=100)\n",
    "print(f'textsplitter:{textsplitter}')\n",
    "\n",
    "docs = loader.load_and_split(textsplitter)\n",
    "print(docs)\n",
    "for doc in docs:\n",
    "    print(f'解析后的文本：{doc}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "import torch\n",
    "EMBEDDING_DEVICE = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "embeddings = HuggingFaceEmbeddings(model_name='GanymedeNil/text2vec-large-chinese',\n",
    "                                                model_kwargs={'device': EMBEDDING_DEVICE})\n",
    "\n",
    "torch_gc()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Tair\n",
    "keys=[]\n",
    "for doc_index in range(len(docs)):\n",
    "    keys.append(f'doc{doc_index}')\n",
    "for key in keys:\n",
    "    print(key)\n",
    "vector_store = Tair.from_documents(docs,embeddings,tair_url=\"redis://120.27.213.45:6380\",keys=keys)  # docs 为Document列表"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pypinyin import lazy_pinyin\n",
    "import datetime\n",
    "\n",
    "VS_ROOT_PATH = os.path.join(os.path.dirname(os.path.dirname(os.path.abspath('__file__'))), \"vector_store\")\n",
    "print(f'{VS_ROOT_PATH}')\n",
    "\n",
    "file = os.path.split(filepath)[-1]\n",
    "print(file)\n",
    "\n",
    "vs_path = os.path.join(VS_ROOT_PATH, f\"\"\"{\"\".join(lazy_pinyin(os.path.splitext(file)[0]))}_FAISS_{datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")}\"\"\")\n",
    "print(f'{vs_path}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "query=\"Tair是什么？\"\n",
    "context = vector_store.similarity_search(query, k=1)\n",
    "context = \"\\n\".join([doc.page_content for doc in context])\n",
    "print(context)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "PROMPT_TEMPLATE = \"\"\"已知信息：\n",
    "{context} \n",
    "\n",
    "根据上述已知信息，简洁和专业的来回答用户的问题。如果无法从中得到答案，请说 “根据已知信息无法回答该问题” 或 “没有提供足够的相关信息”，不允许在答案中添加编造成分，答案请使用中文。 问题是：{question}\"\"\"\n",
    "prompt = PROMPT_TEMPLATE.replace(\"{question}\", query).replace(\"{context}\", context)\n",
    "print(f'prompt:{prompt}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"THUDM/chatglm-6b\", trust_remote_code=True)\n",
    "model = AutoModel.from_pretrained(\"/root/ChatGLM-6B/THUDM/chatglm-6b-int4-qe\", trust_remote_code=True).half().cuda()\n",
    "model = model.eval()\n",
    "response, history = model.chat(tokenizer, prompt, history=[])\n",
    "print(response)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "response, history = model.chat(tokenizer, \"tairvector是什么\", history=[])\n",
    "print(response)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import tair\n",
    "client = tair.Tair(host=\"120.27.213.45\", port=6380)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tairvector_text=[]\n",
    "#tairvector_text.append(str(client.get(\"tairvector\")))\n",
    "tairvector_text.append(\"tairvector是向量数据库\")\n",
    "\n",
    "\n",
    "tairvector_meta=[{\"source\":\"tair\"}]\n",
    "\n",
    "key_tairvector=[]\n",
    "key_tairvector.append(f'tairvector0')\n",
    "Tair.from_texts(tairvector_text,embeddings,tairvector_meta,\"langchain\",\"content\",\"metadata\",tair_url=\"redis://120.27.213.45:6380\",keys=key_tairvector)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "query=\"tairvector是什么？\"\n",
    "context = vector_store.similarity_search(query, k=10)\n",
    "context = \"\\n\".join([doc.page_content for doc in context])\n",
    "\n",
    "\n",
    "PROMPT_TEMPLATE = \"\"\"已知信息：\n",
    "{context} \n",
    "\n",
    "根据上述已知信息，简洁和专业的来回答用户的问题。如果无法从中得到答案，请说 “根据已知信息无法回答该问题” 或 “没有提供足够的相关信息”，不允许在答案中添加编造成分，答案请使用中文。 问题是：{question}\"\"\"\n",
    "prompt = PROMPT_TEMPLATE.replace(\"{question}\", query).replace(\"{context}\", context)\n",
    "print(f'prompt:{prompt}')\n",
    "\n",
    "response, history = model.chat(tokenizer, prompt, history=[])\n",
    "print(response)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "48ac4bd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TairVector是一个基于Python的开源机器学习库，主要用于实现机器学习任务，如分类、聚类、降维等。TairVector使用Python编程语言，并包含了丰富的函数和工具箱，可以方便地完成各种机器学习任务。\n",
      "\n",
      "TairVector的优点包括：\n",
      "\n",
      "- 简单易用的界面，可以方便地安装和使用\n",
      "- 支持多种机器学习算法，包括SVM、KNN、Random Forest等\n",
      "- 可以方便地导入和导出数据集\n",
      "- 可以方便地实现自定义的机器学习算法\n",
      "\n",
      "TairVector也存在一些局限性，例如性能可能不如一些专门的机器学习库，尤其是在处理大型数据集时。但是，TairVector是一个开源的、免费的库，任何人都可以对其进行修改和扩展，这对于实现自己的机器学习算法非常有帮助。\n"
     ]
    }
   ],
   "source": [
    "response, history = model.chat(tokenizer, \"tairvector是什么\", history=[])\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d35a3d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tair\n",
    "client = tair.Tair(host=\"120.27.213.45\", port=6380)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5982259f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain.vectorstores.tair.Tair at 0x7f71b8f880a0>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tairvector_text=[]\n",
    "#tairvector_text.append(str(client.get(\"tairvector\")))\n",
    "tairvector_text.append(\"tairvector是向量数据库\")\n",
    "\n",
    "\n",
    "tairvector_meta=[{\"source\":\"tair\"}]\n",
    "\n",
    "key_tairvector=[]\n",
    "key_tairvector.append(f'tairvector0')\n",
    "Tair.from_texts(tairvector_text,embeddings,tairvector_meta,\"langchain\",\"content\",\"metadata\",tair_url=\"redis://120.27.213.45:6380\",keys=key_tairvector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1402435b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(page_content='tairvector是向量数据库', metadata={'source': 'tair'}), Document(page_content='Tair是阿里云国产自研的云原生内存数据库。', metadata={'source': '/root/caoduanxin/docs/tairQA_cn.txt'}), Document(page_content='提供TairString，TairHash，TairGIS，TairCpc，TairBloom等多种扩展数据结构，极大降低用户的开发成本，更有利于业务创新。', metadata={'source': '/root/caoduanxin/docs/tairQA_cn.txt'}), Document(page_content='为什么选择云原生内存数据库Tair', metadata={'source': '/root/caoduanxin/docs/tairQA_cn.txt'}), Document(page_content='同时，Tair与新型存储介质——持久内存的高效结合，相比内存，成本降低30%以上，并能做到数据持久化和提供近似于内存的性能。', metadata={'source': '/root/caoduanxin/docs/tairQA_cn.txt'}), Document(page_content='目前，Tair已广泛应用于政务、金融、制造、医疗和泛互联网等各行业客户，满足客户的高速查询和计算场景。', metadata={'source': '/root/caoduanxin/docs/tairQA_cn.txt'}), Document(page_content='同时推出Tair集群版无感扩缩容方案，解决当前业界扩缩容方案对业务有损的问题。', metadata={'source': '/root/caoduanxin/docs/tairQA_cn.txt'}), Document(page_content='在完全兼容Redis的基础上，提供了丰富的数据模型和企业级能力来帮助客户构建实时在线场景。', metadata={'source': '/root/caoduanxin/docs/tairQA_cn.txt'}), Document(page_content='从访问延时、持久化需求、整体成本这三个核心维度考量，', metadata={'source': '/root/caoduanxin/docs/tairQA_cn.txt'}), Document(page_content='更丰富的数据结构', metadata={'source': '/root/caoduanxin/docs/tairQA_cn.txt'})]\n",
      "prompt:已知信息：\n",
      "tairvector是向量数据库\n",
      "Tair是阿里云国产自研的云原生内存数据库。\n",
      "提供TairString，TairHash，TairGIS，TairCpc，TairBloom等多种扩展数据结构，极大降低用户的开发成本，更有利于业务创新。\n",
      "为什么选择云原生内存数据库Tair\n",
      "同时，Tair与新型存储介质——持久内存的高效结合，相比内存，成本降低30%以上，并能做到数据持久化和提供近似于内存的性能。\n",
      "目前，Tair已广泛应用于政务、金融、制造、医疗和泛互联网等各行业客户，满足客户的高速查询和计算场景。\n",
      "同时推出Tair集群版无感扩缩容方案，解决当前业界扩缩容方案对业务有损的问题。\n",
      "在完全兼容Redis的基础上，提供了丰富的数据模型和企业级能力来帮助客户构建实时在线场景。\n",
      "从访问延时、持久化需求、整体成本这三个核心维度考量，\n",
      "更丰富的数据结构 \n",
      "\n",
      "根据上述已知信息，简洁和专业的来回答用户的问题。如果无法从中得到答案，请说 “根据已知信息无法回答该问题” 或 “没有提供足够的相关信息”，不允许在答案中添加编造成分，答案请使用中文。 问题是：tairvector是什么？\n",
      "TairVector 是一个云原生内存数据库，提供多种扩展数据结构，如 TairString、TairHash、TairGIS、TairCpc 和 Tair Bloom 等，可以极大降低用户的开发成本，并有利于业务创新。TairVector 由阿里云国产自研，与持久内存的结合相比，成本降低 30% 以上，并能提供近似于内存的性能。TairVector 已广泛应用于政务、金融、制造、医疗和泛互联网等各行业客户，满足客户的高速查询和计算场景。同时推出集群版无感扩缩容方案，解决当前业界扩缩容方案对业务有损的问题。\n"
     ]
    }
   ],
   "source": [
    "query=\"tairvector是什么？\"\n",
    "context = vector_store.similarity_search(query, k=10)\n",
    "context = \"\\n\".join([doc.page_content for doc in context])\n",
    "\n",
    "\n",
    "PROMPT_TEMPLATE = \"\"\"已知信息：\n",
    "{context} \n",
    "\n",
    "根据上述已知信息，简洁和专业的来回答用户的问题。如果无法从中得到答案，请说 “根据已知信息无法回答该问题” 或 “没有提供足够的相关信息”，不允许在答案中添加编造成分，答案请使用中文。 问题是：{question}\"\"\"\n",
    "prompt = PROMPT_TEMPLATE.replace(\"{question}\", query).replace(\"{context}\", context)\n",
    "print(f'prompt:{prompt}')\n",
    "\n",
    "response, history = model.chat(tokenizer, prompt, history=[])\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aaf6de1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}